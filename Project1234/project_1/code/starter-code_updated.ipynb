{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the problem you are finding answers for from the data given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "sat2017_df = pd.read_csv('../data/sat_2017.csv') #dataframe sat_2017.csv\n",
    "act2017_df = pd.read_csv('../data/act_2017.csv') #dataframe act_2017.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "sat2017_df.head(10) #displays first 10 rows of sat2017_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act2017_df.head(10) #displays first 10 rows of act2017_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "For sat2017_df 'State' shows the various states of the US, 'Participation' shows the participation rates of each state, 'Evidence-Based Reading and Writing' is the score for the English Reading and Writing portion for each state, 'Math' is the score for the math portion for each state and 'Total' is the Evidence-Based Reading and Writing score and Math score for each state.\n",
    "\n",
    "For act2017_df 'State' shows the various states of the US, 'Participation' shows the participation rates of each state, 'English' is the score for the English porition of each state, 'Math' is the score for the Math portion of each state, 'Reading' is the score for the Reading portion of each state, 'Science' is the score for the Science portion of each state and 'Composite' is the average of Math, English, Reading and Science scores combined for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The data looks complete but it's odd that only ACT scores include the row with 'National' under the 'State' column after looking at the total rows for both sat2017_df.info() and act2017_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There is a row in the ACT dataframe with the State column as 'National' and the participation rates are object data type so you can't perform arithemtic functions on it.\n",
    "Each SAT subtest possible minimum score is 200 and maximum possible score is 800\n",
    "Each ACT subtest possible minimum score is 1 and maximum possible score is 36. The ACT composite possible minimum score is 1 and maximum possible score is 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#code\n",
    "act2017_df.info() #To see the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   State                               51 non-null     object\n",
      " 1   Participation                       51 non-null     object\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64 \n",
      " 3   Math                                51 non-null     int64 \n",
      " 4   Total                               51 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sat2017_df.info() #To see the data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Participation data are object data type for both dataframes so you can't perform arithmetic functions on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to convert the data type for Participation column from object to float\n",
    "def partipation_convert(string):      \n",
    "    string = string.replace('%','')\n",
    "    string = float(string)/100\n",
    "    return string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "sat2017_df['Participation']=sat2017_df['Participation'].apply(partipation_convert)\n",
    "#Applying partipation_convert to sat2017_df['Participation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "act2017_df['Participation']=act2017_df['Participation'].apply(partipation_convert)\n",
    "#Applying partipation_convert to sat2017_df['Participation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "act2017_df['Composite']=act2017_df['Composite'].str.replace('x','') \n",
    "#Replacing the 'x' in one of the Composite entries with blank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "act2017_df['Composite']=act2017_df['Composite'].astype(float)\n",
    "#Change act2017_df['Composite'] data type to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   State                               51 non-null     object \n",
      " 1   Participation                       51 non-null     float64\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64  \n",
      " 3   Math                                51 non-null     int64  \n",
      " 4   Total                               51 non-null     int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Code:\n",
    "sat2017_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "act2017_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "sat2017_df.rename(columns={'State':'state', 'Participation':'sat2017_participation_rate', 'Evidence-Based Reading and Writing':'sat2017_avg_evidence_based_reading_and_writing_score', 'Math':'sat2017_avg_math_score',\n",
    "       'Total':'sat2017_avg_total_score'},inplace = True)\n",
    "#Renaming sat2017_df columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "act2017_df.rename(columns={'State':'state', 'Participation':'act2017_participation_rate', 'English':'act2017_avg_english_score', 'Math':'act2017_avg_math_score', 'Reading':'act2017_avg_reading_score', 'Science':'act2017_avg_science_score',\n",
    "       'Composite':'act2017_composite_score'},inplace = True)\n",
    "#Renaming act2017_df columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|sat2017_df/act2017_df/sat2018_df/act2018_df|Shows each state of the US| \n",
    "|sat2017_participation_rate|float64|sat2017_df|Shows SAT participation rate of each state for 2017|\n",
    "|sat2017_avg_evidence_based_reading_and_writing_score|int64|sat2017_df|Shows SAT average evidence based reading and writing score of each state for 2017|\n",
    "|sat2017_avg_math_score|int64|sat2017_df|Shows SAT average math score for each state for 2017|\n",
    "|sat2017_avg_total_score|int64|sat2017_df|Shows SAT average total score for each state for 2017|\n",
    "sat2018_participation_rate|float64|sat2018_df|Shows SAT participation rate of each state for 2018|\n",
    "|sat2018_avg_evidence_based_reading_and_writing_score|int64|sat2018_df|Shows SAT average evidence based reading and writing score of each state for 2018|\n",
    "|sat2018_avg_math_score|int64|sat2018_df|Shows SAT average math score for each state for 2018|\n",
    "|sat2018_avg_total_score|int64|sat2018_df|Shows SAT average total score for each state for 2018|\n",
    "|act2017_participation_rate|object|act2017_df|Shows ACT participation rate of each state for 2017|\n",
    "|act2017_avg_english_score|float64|act2017_df|Shows ACT average english score of each state for 2017|\n",
    "|act2017_avg_math_score|float64|act2017_df|Shows ACT average math score of each state for 2017|\n",
    "|act2017_avg_reading_score|float64|act2017_df|Shows ACT average reading score of each state for 2017|\n",
    "|act2017_avg_science_score|float64|act2017_df|Shows ACT average science score of each state for 2017|\n",
    "|act2017_composite_score|float64|act2017_df|Shows ACT composite score of each state for 2017|\n",
    "|act2017_participation_rate|object|act2018_df|Shows ACT participation rate of each state for 2018|\n",
    "|act2018_avg_english_score|float64|act2018_df|Shows ACT average english score of each state for 2018|\n",
    "|act2018_avg_math_score|float64|act2018_df|Shows ACT average math score of each state for 2018|\n",
    "|act2018_avg_reading_score|float64|act2018_df|Shows ACT average reading score of each state for 2018|\n",
    "|act2018_avg_science_score|float64|act2018_df|Shows ACT average science score of each state for 2018|\n",
    "|act2018_composite_score|float64|act2018_df|Shows ACT composite score of each state for 2018|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "act2017_df.drop(index = 0,inplace = True)\n",
    "#Dropping the row with state \"National\" in act2017_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act2017_participation_rate</th>\n",
       "      <th>act2017_avg_english_score</th>\n",
       "      <th>act2017_avg_math_score</th>\n",
       "      <th>act2017_avg_reading_score</th>\n",
       "      <th>act2017_avg_science_score</th>\n",
       "      <th>act2017_composite_score</th>\n",
       "      <th>sat2017_participation_rate</th>\n",
       "      <th>sat2017_avg_evidence_based_reading_and_writing_score</th>\n",
       "      <th>sat2017_avg_math_score</th>\n",
       "      <th>sat2017_avg_total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>1.00</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.11</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>0.31</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>0.18</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>0.32</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.73</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  state  act2017_participation_rate  \\\n",
       "0               Alabama                        1.00   \n",
       "1                Alaska                        0.65   \n",
       "2               Arizona                        0.62   \n",
       "3              Arkansas                        1.00   \n",
       "4            California                        0.31   \n",
       "5              Colorado                        1.00   \n",
       "6           Connecticut                        0.31   \n",
       "7              Delaware                        0.18   \n",
       "8  District of Columbia                        0.32   \n",
       "9               Florida                        0.73   \n",
       "\n",
       "   act2017_avg_english_score  act2017_avg_math_score  \\\n",
       "0                       18.9                    18.4   \n",
       "1                       18.7                    19.8   \n",
       "2                       18.6                    19.8   \n",
       "3                       18.9                    19.0   \n",
       "4                       22.5                    22.7   \n",
       "5                       20.1                    20.3   \n",
       "6                       25.5                    24.6   \n",
       "7                       24.1                    23.4   \n",
       "8                       24.4                    23.5   \n",
       "9                       19.0                    19.4   \n",
       "\n",
       "   act2017_avg_reading_score  act2017_avg_science_score  \\\n",
       "0                       19.7                       19.4   \n",
       "1                       20.4                       19.9   \n",
       "2                       20.1                       19.8   \n",
       "3                       19.7                       19.5   \n",
       "4                       23.1                       22.2   \n",
       "5                       21.2                       20.9   \n",
       "6                       25.6                       24.6   \n",
       "7                       24.8                       23.6   \n",
       "8                       24.9                       23.5   \n",
       "9                       21.0                       19.4   \n",
       "\n",
       "   act2017_composite_score  sat2017_participation_rate  \\\n",
       "0                     19.2                        0.05   \n",
       "1                     19.8                        0.38   \n",
       "2                     19.7                        0.30   \n",
       "3                     19.4                        0.03   \n",
       "4                     22.8                        0.53   \n",
       "5                     20.8                        0.11   \n",
       "6                     25.2                        1.00   \n",
       "7                     24.1                        1.00   \n",
       "8                     24.2                        1.00   \n",
       "9                     19.8                        0.83   \n",
       "\n",
       "   sat2017_avg_evidence_based_reading_and_writing_score  \\\n",
       "0                                                593      \n",
       "1                                                547      \n",
       "2                                                563      \n",
       "3                                                614      \n",
       "4                                                531      \n",
       "5                                                606      \n",
       "6                                                530      \n",
       "7                                                503      \n",
       "8                                                482      \n",
       "9                                                520      \n",
       "\n",
       "   sat2017_avg_math_score  sat2017_avg_total_score  \n",
       "0                     572                     1165  \n",
       "1                     533                     1080  \n",
       "2                     553                     1116  \n",
       "3                     594                     1208  \n",
       "4                     524                     1055  \n",
       "5                     595                     1201  \n",
       "6                     512                     1041  \n",
       "7                     492                      996  \n",
       "8                     468                      950  \n",
       "9                     497                     1017  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "data_merge2017 = pd.merge(act2017_df,sat2017_df, on='state', how='outer')\n",
    "#Merging act2017_df and sat2017_df together and storing it in data_merge2017\n",
    "data_merge2017.head(10)\n",
    "#Displaying first 10 rows of data_merge2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "data_merge2017.to_csv(r'../data/data_merge2017.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variables sat2018_df and act2018_df to store SAT2018 and ACT2018 scores\n",
    "sat2018_df = pd.read_csv('../data/sat_2018.csv')\n",
    "act2018_df = pd.read_csv('../data/act_2018_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying partipation_convert to sat2018_df['Participation'] to remove '%' sign and convert the data to float\n",
    "sat2018_df['Participation']=sat2018_df['Participation'].apply(partipation_convert)\n",
    "#Apply function to act2018_df and use lambda x function to convert data to float\n",
    "act2018_df['Percentage of Students Tested']=act2018_df['Percentage of Students Tested'].apply(lambda x: float(x)/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   State                               51 non-null     object \n",
      " 1   Participation                       51 non-null     float64\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64  \n",
      " 3   Math                                51 non-null     int64  \n",
      " 4   Total                               51 non-null     int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sat2018_df.info() #Check Participation is float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   State                          51 non-null     object \n",
      " 1   Percentage of Students Tested  51 non-null     float64\n",
      " 2   Average Composite Score        51 non-null     float64\n",
      " 3   Average English Score          51 non-null     float64\n",
      " 4   Average Math Score             51 non-null     float64\n",
      " 5   Average Reading Score          51 non-null     float64\n",
      " 6   Average Science Score          51 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "act2018_df.info() #Check Percentage of Students Tested is float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rearranging act2018_df columns to match respective act2017_df\n",
    "act2018_df = act2018_df[['State', 'Percentage of Students Tested','Average English Score', 'Average Math Score', 'Average Reading Score','Average Science Score','Average Composite Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat2018_df.rename(columns={'State':'state', 'Participation':'sat2018_participation_rate', 'Evidence-Based Reading and Writing':'sat2018_avg_evidence_based_reading_and_writing_score', 'Math':'sat2018_avg_math_score',\n",
    "       'Total':'sat2018_avg_total_score'},inplace = True)\n",
    "#Renaming sat2018_df columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "act2018_df.rename(columns={'State':'state', 'Percentage of Students Tested':'act2018_participation_rate', 'Average English Score':'act2018_avg_english_score', 'Average Math Score':'act2018_avg_math_score', 'Average Reading Score':'act2018_avg_reading_score', 'Average Science Score':'act2018_avg_science_score',\n",
    "       'Average Composite Score':'act2018_composite_score'},inplace = True)\n",
    "#Renaming act2018_df columns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merge2018 = pd.merge(act2018_df,sat2018_df, on='state', how='outer') #Merging act2018_df and sat2018_df as data_merge2018\n",
    "data_merge2018.to_csv(r'../data/data_merge2018.csv',index=False) #Saving data_merge2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merge = pd.merge(data_merge2017,data_merge2018, on='state', how='outer') #Merging data_merge2017 and data_merge2018 as all_merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act2017_participation_rate</th>\n",
       "      <th>act2017_avg_english_score</th>\n",
       "      <th>act2017_avg_math_score</th>\n",
       "      <th>act2017_avg_reading_score</th>\n",
       "      <th>act2017_avg_science_score</th>\n",
       "      <th>act2017_composite_score</th>\n",
       "      <th>sat2017_participation_rate</th>\n",
       "      <th>sat2017_avg_evidence_based_reading_and_writing_score</th>\n",
       "      <th>sat2017_avg_math_score</th>\n",
       "      <th>...</th>\n",
       "      <th>act2018_participation_rate</th>\n",
       "      <th>act2018_avg_english_score</th>\n",
       "      <th>act2018_avg_math_score</th>\n",
       "      <th>act2018_avg_reading_score</th>\n",
       "      <th>act2018_avg_science_score</th>\n",
       "      <th>act2018_composite_score</th>\n",
       "      <th>sat2018_participation_rate</th>\n",
       "      <th>sat2018_avg_evidence_based_reading_and_writing_score</th>\n",
       "      <th>sat2018_avg_math_score</th>\n",
       "      <th>sat2018_avg_total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>21.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18.2</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1.00</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  act2017_participation_rate  act2017_avg_english_score  \\\n",
       "0     Alabama                        1.00                       18.9   \n",
       "1      Alaska                        0.65                       18.7   \n",
       "2     Arizona                        0.62                       18.6   \n",
       "3    Arkansas                        1.00                       18.9   \n",
       "4  California                        0.31                       22.5   \n",
       "\n",
       "   act2017_avg_math_score  act2017_avg_reading_score  \\\n",
       "0                    18.4                       19.7   \n",
       "1                    19.8                       20.4   \n",
       "2                    19.8                       20.1   \n",
       "3                    19.0                       19.7   \n",
       "4                    22.7                       23.1   \n",
       "\n",
       "   act2017_avg_science_score  act2017_composite_score  \\\n",
       "0                       19.4                     19.2   \n",
       "1                       19.9                     19.8   \n",
       "2                       19.8                     19.7   \n",
       "3                       19.5                     19.4   \n",
       "4                       22.2                     22.8   \n",
       "\n",
       "   sat2017_participation_rate  \\\n",
       "0                        0.05   \n",
       "1                        0.38   \n",
       "2                        0.30   \n",
       "3                        0.03   \n",
       "4                        0.53   \n",
       "\n",
       "   sat2017_avg_evidence_based_reading_and_writing_score  \\\n",
       "0                                                593      \n",
       "1                                                547      \n",
       "2                                                563      \n",
       "3                                                614      \n",
       "4                                                531      \n",
       "\n",
       "   sat2017_avg_math_score  ...  act2018_participation_rate  \\\n",
       "0                     572  ...                        1.00   \n",
       "1                     533  ...                        0.33   \n",
       "2                     553  ...                        0.66   \n",
       "3                     594  ...                        1.00   \n",
       "4                     524  ...                        0.27   \n",
       "\n",
       "   act2018_avg_english_score  act2018_avg_math_score  \\\n",
       "0                       18.9                    18.3   \n",
       "1                       19.8                    20.6   \n",
       "2                       18.2                    19.4   \n",
       "3                       19.1                    18.9   \n",
       "4                       22.5                    22.5   \n",
       "\n",
       "   act2018_avg_reading_score  act2018_avg_science_score  \\\n",
       "0                       19.6                       19.0   \n",
       "1                       21.6                       20.7   \n",
       "2                       19.5                       19.2   \n",
       "3                       19.7                       19.4   \n",
       "4                       23.0                       22.1   \n",
       "\n",
       "   act2018_composite_score  sat2018_participation_rate  \\\n",
       "0                     19.1                        0.06   \n",
       "1                     20.8                        0.43   \n",
       "2                     19.2                        0.29   \n",
       "3                     19.4                        0.05   \n",
       "4                     22.7                        0.60   \n",
       "\n",
       "   sat2018_avg_evidence_based_reading_and_writing_score  \\\n",
       "0                                                595      \n",
       "1                                                562      \n",
       "2                                                577      \n",
       "3                                                592      \n",
       "4                                                540      \n",
       "\n",
       "   sat2018_avg_math_score  sat2018_avg_total_score  \n",
       "0                     571                     1166  \n",
       "1                     544                     1106  \n",
       "2                     572                     1149  \n",
       "3                     576                     1169  \n",
       "4                     536                     1076  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act2017_participation_rate</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.652549</td>\n",
       "      <td>0.321408</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2017_avg_english_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.931373</td>\n",
       "      <td>2.353677</td>\n",
       "      <td>16.30</td>\n",
       "      <td>19.000</td>\n",
       "      <td>20.70</td>\n",
       "      <td>23.300</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2017_avg_math_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.182353</td>\n",
       "      <td>1.981989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>19.400</td>\n",
       "      <td>20.90</td>\n",
       "      <td>23.100</td>\n",
       "      <td>25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2017_avg_reading_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.013725</td>\n",
       "      <td>2.067271</td>\n",
       "      <td>18.10</td>\n",
       "      <td>20.450</td>\n",
       "      <td>21.80</td>\n",
       "      <td>24.150</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2017_avg_science_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.041176</td>\n",
       "      <td>3.182463</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.900</td>\n",
       "      <td>21.30</td>\n",
       "      <td>22.750</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2017_composite_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.519608</td>\n",
       "      <td>2.020695</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.800</td>\n",
       "      <td>21.40</td>\n",
       "      <td>23.600</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2017_participation_rate</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.398039</td>\n",
       "      <td>0.352766</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2017_avg_evidence_based_reading_and_writing_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>569.117647</td>\n",
       "      <td>45.666901</td>\n",
       "      <td>482.00</td>\n",
       "      <td>533.500</td>\n",
       "      <td>559.00</td>\n",
       "      <td>613.000</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2017_avg_math_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>547.627451</td>\n",
       "      <td>84.909119</td>\n",
       "      <td>52.00</td>\n",
       "      <td>522.000</td>\n",
       "      <td>548.00</td>\n",
       "      <td>599.000</td>\n",
       "      <td>651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2017_avg_total_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1126.098039</td>\n",
       "      <td>92.494812</td>\n",
       "      <td>950.00</td>\n",
       "      <td>1055.500</td>\n",
       "      <td>1107.00</td>\n",
       "      <td>1212.000</td>\n",
       "      <td>1295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_participation_rate</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.616471</td>\n",
       "      <td>0.340810</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_avg_english_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.988235</td>\n",
       "      <td>2.446356</td>\n",
       "      <td>16.60</td>\n",
       "      <td>19.100</td>\n",
       "      <td>20.20</td>\n",
       "      <td>23.700</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_avg_math_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.125490</td>\n",
       "      <td>2.035765</td>\n",
       "      <td>17.80</td>\n",
       "      <td>19.400</td>\n",
       "      <td>20.70</td>\n",
       "      <td>23.150</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_avg_reading_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>22.015686</td>\n",
       "      <td>2.167245</td>\n",
       "      <td>18.00</td>\n",
       "      <td>20.450</td>\n",
       "      <td>21.60</td>\n",
       "      <td>24.100</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_avg_science_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.345098</td>\n",
       "      <td>1.870114</td>\n",
       "      <td>17.90</td>\n",
       "      <td>19.850</td>\n",
       "      <td>21.10</td>\n",
       "      <td>23.050</td>\n",
       "      <td>24.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2018_composite_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>21.486275</td>\n",
       "      <td>2.106278</td>\n",
       "      <td>17.70</td>\n",
       "      <td>19.950</td>\n",
       "      <td>21.30</td>\n",
       "      <td>23.550</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2018_participation_rate</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.457451</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.775</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2018_avg_evidence_based_reading_and_writing_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>563.686275</td>\n",
       "      <td>47.502627</td>\n",
       "      <td>480.00</td>\n",
       "      <td>534.500</td>\n",
       "      <td>552.00</td>\n",
       "      <td>610.500</td>\n",
       "      <td>643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2018_avg_math_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>556.235294</td>\n",
       "      <td>47.772623</td>\n",
       "      <td>480.00</td>\n",
       "      <td>522.500</td>\n",
       "      <td>544.00</td>\n",
       "      <td>593.500</td>\n",
       "      <td>655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sat2018_avg_total_score</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1120.019608</td>\n",
       "      <td>94.155083</td>\n",
       "      <td>977.00</td>\n",
       "      <td>1057.500</td>\n",
       "      <td>1098.00</td>\n",
       "      <td>1204.000</td>\n",
       "      <td>1298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count         mean  \\\n",
       "act2017_participation_rate                           51.0     0.652549   \n",
       "act2017_avg_english_score                            51.0    20.931373   \n",
       "act2017_avg_math_score                               51.0    21.182353   \n",
       "act2017_avg_reading_score                            51.0    22.013725   \n",
       "act2017_avg_science_score                            51.0    21.041176   \n",
       "act2017_composite_score                              51.0    21.519608   \n",
       "sat2017_participation_rate                           51.0     0.398039   \n",
       "sat2017_avg_evidence_based_reading_and_writing_...   51.0   569.117647   \n",
       "sat2017_avg_math_score                               51.0   547.627451   \n",
       "sat2017_avg_total_score                              51.0  1126.098039   \n",
       "act2018_participation_rate                           51.0     0.616471   \n",
       "act2018_avg_english_score                            51.0    20.988235   \n",
       "act2018_avg_math_score                               51.0    21.125490   \n",
       "act2018_avg_reading_score                            51.0    22.015686   \n",
       "act2018_avg_science_score                            51.0    21.345098   \n",
       "act2018_composite_score                              51.0    21.486275   \n",
       "sat2018_participation_rate                           51.0     0.457451   \n",
       "sat2018_avg_evidence_based_reading_and_writing_...   51.0   563.686275   \n",
       "sat2018_avg_math_score                               51.0   556.235294   \n",
       "sat2018_avg_total_score                              51.0  1120.019608   \n",
       "\n",
       "                                                          std     min  \\\n",
       "act2017_participation_rate                           0.321408    0.08   \n",
       "act2017_avg_english_score                            2.353677   16.30   \n",
       "act2017_avg_math_score                               1.981989   18.00   \n",
       "act2017_avg_reading_score                            2.067271   18.10   \n",
       "act2017_avg_science_score                            3.182463    2.30   \n",
       "act2017_composite_score                              2.020695   17.80   \n",
       "sat2017_participation_rate                           0.352766    0.02   \n",
       "sat2017_avg_evidence_based_reading_and_writing_...  45.666901  482.00   \n",
       "sat2017_avg_math_score                              84.909119   52.00   \n",
       "sat2017_avg_total_score                             92.494812  950.00   \n",
       "act2018_participation_rate                           0.340810    0.07   \n",
       "act2018_avg_english_score                            2.446356   16.60   \n",
       "act2018_avg_math_score                               2.035765   17.80   \n",
       "act2018_avg_reading_score                            2.167245   18.00   \n",
       "act2018_avg_science_score                            1.870114   17.90   \n",
       "act2018_composite_score                              2.106278   17.70   \n",
       "sat2018_participation_rate                           0.373143    0.02   \n",
       "sat2018_avg_evidence_based_reading_and_writing_...  47.502627  480.00   \n",
       "sat2018_avg_math_score                              47.772623  480.00   \n",
       "sat2018_avg_total_score                             94.155083  977.00   \n",
       "\n",
       "                                                         25%      50%  \\\n",
       "act2017_participation_rate                             0.310     0.69   \n",
       "act2017_avg_english_score                             19.000    20.70   \n",
       "act2017_avg_math_score                                19.400    20.90   \n",
       "act2017_avg_reading_score                             20.450    21.80   \n",
       "act2017_avg_science_score                             19.900    21.30   \n",
       "act2017_composite_score                               19.800    21.40   \n",
       "sat2017_participation_rate                             0.040     0.38   \n",
       "sat2017_avg_evidence_based_reading_and_writing_...   533.500   559.00   \n",
       "sat2017_avg_math_score                               522.000   548.00   \n",
       "sat2017_avg_total_score                             1055.500  1107.00   \n",
       "act2018_participation_rate                             0.285     0.66   \n",
       "act2018_avg_english_score                             19.100    20.20   \n",
       "act2018_avg_math_score                                19.400    20.70   \n",
       "act2018_avg_reading_score                             20.450    21.60   \n",
       "act2018_avg_science_score                             19.850    21.10   \n",
       "act2018_composite_score                               19.950    21.30   \n",
       "sat2018_participation_rate                             0.045     0.52   \n",
       "sat2018_avg_evidence_based_reading_and_writing_...   534.500   552.00   \n",
       "sat2018_avg_math_score                               522.500   544.00   \n",
       "sat2018_avg_total_score                             1057.500  1098.00   \n",
       "\n",
       "                                                         75%     max  \n",
       "act2017_participation_rate                             1.000     1.0  \n",
       "act2017_avg_english_score                             23.300    25.5  \n",
       "act2017_avg_math_score                                23.100    25.3  \n",
       "act2017_avg_reading_score                             24.150    26.0  \n",
       "act2017_avg_science_score                             22.750    24.9  \n",
       "act2017_composite_score                               23.600    25.5  \n",
       "sat2017_participation_rate                             0.660     1.0  \n",
       "sat2017_avg_evidence_based_reading_and_writing_...   613.000   644.0  \n",
       "sat2017_avg_math_score                               599.000   651.0  \n",
       "sat2017_avg_total_score                             1212.000  1295.0  \n",
       "act2018_participation_rate                             1.000     1.0  \n",
       "act2018_avg_english_score                             23.700    26.0  \n",
       "act2018_avg_math_score                                23.150    25.2  \n",
       "act2018_avg_reading_score                             24.100    26.1  \n",
       "act2018_avg_science_score                             23.050    24.9  \n",
       "act2018_composite_score                               23.550    25.6  \n",
       "sat2018_participation_rate                             0.775     1.0  \n",
       "sat2018_avg_evidence_based_reading_and_writing_...   610.500   643.0  \n",
       "sat2018_avg_math_score                               593.500   655.0  \n",
       "sat2018_avg_total_score                             1204.000  1298.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "all_merge.describe().T #Transposing all_merge describe features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "def st_dev(x):\n",
    "    \n",
    "    mean = np.mean(x) #mean of x\n",
    "    sq = [(i - mean)**2 for i in x] #Calculate the square of the distance between each datapoint of x and the mean\n",
    "        \n",
    "    return (sum(sq)/len(x))**0.5 #return the standard deviation for x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "sd = {key : st_dev(all_merge[key]) for key in all_merge.select_dtypes(['float', 'int64']).columns}\n",
    "# Use st_dev in dictionary comprehension to store standard deivation for each column in all_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act2017_participation_rate': 0.3182417575123181,\n",
       " 'act2017_avg_english_score': 2.3304876369363363,\n",
       " 'act2017_avg_math_score': 1.9624620273436781,\n",
       " 'act2017_avg_reading_score': 2.0469029314842646,\n",
       " 'act2017_avg_science_score': 3.151107895464408,\n",
       " 'act2017_composite_score': 2.000786081581989,\n",
       " 'sat2017_participation_rate': 0.3492907076664507,\n",
       " 'sat2017_avg_evidence_based_reading_and_writing_score': 45.21697020437866,\n",
       " 'sat2017_avg_math_score': 84.07255521608297,\n",
       " 'sat2017_avg_total_score': 91.58351056778743,\n",
       " 'act2018_participation_rate': 0.33745194881997503,\n",
       " 'act2018_avg_english_score': 2.4222536143202795,\n",
       " 'act2018_avg_math_score': 2.015707255555717,\n",
       " 'act2018_avg_reading_score': 2.145891884510421,\n",
       " 'act2018_avg_science_score': 1.8516885484833543,\n",
       " 'act2018_composite_score': 2.0855261815801147,\n",
       " 'sat2018_participation_rate': 0.3694661922353942,\n",
       " 'sat2018_avg_evidence_based_reading_and_writing_score': 47.03460978357609,\n",
       " 'sat2018_avg_math_score': 47.30194550378352,\n",
       " 'sat2018_avg_total_score': 93.22742384464433}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd #To show manaually calcualted standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3182417575123181\n",
      "2.3304876369363363\n",
      "1.9624620273436781\n",
      "2.0469029314842646\n",
      "3.151107895464408\n",
      "2.000786081581989\n",
      "0.3492907076664507\n",
      "45.21697020437866\n",
      "84.07255521608297\n",
      "91.58351056778743\n",
      "0.33745194881997503\n",
      "2.4222536143202795\n",
      "2.015707255555717\n",
      "2.145891884510421\n",
      "1.8516885484833543\n",
      "2.0855261815801147\n",
      "0.3694661922353942\n",
      "47.03460978357609\n",
      "47.30194550378352\n",
      "93.22742384464433\n"
     ]
    }
   ],
   "source": [
    "for key in all_merge.select_dtypes(['float', 'int64']).columns:\n",
    "    print(np.std(all_merge[key]))\n",
    "#To show numpy standard deviation calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Both the manually calculated standard deviations and numpy std method are the same and they are quite close to the values of pandas describe standard deviations but not the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#code\n",
    "sat2017_partmax = all_merge.sort_values('sat2017_participation_rate',ascending=False).head()\n",
    "sat2017_partmin = all_merge.sort_values('sat2017_participation_rate').head()\n",
    "sat2018_partmax = all_merge.sort_values('sat2018_participation_rate',ascending=False).head()\n",
    "sat2018_partmin = all_merge.sort_values('sat2018_participation_rate').head()\n",
    "act2017_partmax = all_merge.sort_values('act2017_participation_rate',ascending=False).head()\n",
    "act2017_partmin = all_merge.sort_values('act2017_participation_rate').head()\n",
    "act2018_partmax = all_merge.sort_values('act2018_participation_rate',ascending=False).head()\n",
    "act2018_partmin = all_merge.sort_values('act2018_participation_rate').head()\n",
    "sat2017_totalmax= all_merge.sort_values('sat2017_avg_total_score',ascending = False)[['state','sat2017_avg_total_score']].head()\n",
    "sat2017_totalmin= all_merge.sort_values('sat2017_avg_total_score')[['state','sat2017_avg_total_score']].head()\n",
    "sat2018_totalmax= all_merge.sort_values('sat2018_avg_total_score',ascending = False)[['state','sat2018_avg_total_score']].head()\n",
    "sat2018_totalmin= all_merge.sort_values('sat2018_avg_total_score')[['state','sat2018_avg_total_score']].head()\n",
    "act2017_totalmax= all_merge.sort_values('act2017_composite_score',ascending = False)[['state','act2017_composite_score']].head()\n",
    "act2017_totalmin= all_merge.sort_values('act2017_composite_score')[['state','act2017_composite_score']].head()\n",
    "act2018_totalmax= all_merge.sort_values('act2018_composite_score',ascending = False)[['state','act2018_composite_score']].head()\n",
    "act2018_totalmin= all_merge.sort_values('act2018_composite_score')[['state','act2018_composite_score']].head()\n",
    "sat_partchange = all_merge[(all_merge['sat2017_participation_rate']==1.0)&(all_merge['sat2018_participation_rate']<1.0)]\n",
    "act_partchange = all_merge[(all_merge['act2017_participation_rate']==1.0)&(all_merge['act2018_participation_rate']<1.0)]\n",
    "sat_greater50 = all_merge[(all_merge['sat2017_participation_rate']>0.5)|(all_merge['sat2018_participation_rate']>0.5)]\n",
    "act_greater50 = all_merge[(all_merge['act2017_participation_rate']>0.5)|(all_merge['act2018_participation_rate']>0.5)]['state']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States with highest SAT 2017 participation rates are District of Columbia, Michigan, Connecticut and Delaware\n",
    "States with lowest SAT 2017 participation rates are North Dakota, Mississippi and Iowa\n",
    "States with highest SAT 2018 participation rates are Colorado, Connecticut, Delaware, Michigan and Idaho\n",
    "State with lowest SAT 2018 participation rate is North Dakota\n",
    "States with highest ACT 2017 participation rates are Alabama, Kentucky, Wisconsin, Utah, Tennessee, South Carolina, Oklahoma, North Carolina, Nevada, Montana, Mississippi, Minnesota, Louisiana, Missouri, Wyoming, Colorado and Arkansas\n",
    "State with lowest ACT 2017 participation rate is Maine\n",
    "States with highest ACT 2018 participation rates are Alabama, Kentucky, Wisconsin, Utah, Tennessee, South Carolina, Oklahoma, Ohio, North Carolina, Nevada, Nebraska, Montana, Mississippi, Louisiana, Missouri, Wyoming and Arkansas\n",
    "State with lowest ACT 2018 participation rate is Maine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State with highest SAT 2017 total score is Minnesota\n",
    "State with lowest SAT 2017 total score is District of Columbia\t\n",
    "State with highest SAT 2018 total score is Minnesota\n",
    "State with lowest SAT 2018 total score is District of Columbia\t\n",
    "State with highest ACT 2017 composite score is New Hampshire\t\n",
    "State with lowest ACT 2017 composite score is Nevada\t\n",
    "State with highest ACT 2018 composite score is Connecticut\t\n",
    "State with lowest ACT 2018 composite score is Nevada\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District of Columbia saw a SAT participation rate change from 100% in 2017 to 92% in 2018 which is 8% decrease year to year\n",
    "Colorado saw a ACT participation rate change from 100% to 30% which is a 70% decrease year to year and Minnesota saw a ACT participation rate change from 100% to 99% which is a 1% decrease year to year\n",
    "States that had SAT participation rates >50% either year are California, Colorado, Connecticut, Delaware,          District of Columbia, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Maine, Maryland, Massachusetts, Michigan,    New Hampshire, New Jersey, New York, North Carolina, Pennsylvania, Rhode Island, South Carolina, Texas, Vermont, Virginia, Washington\n",
    "States that had ACT participation rates >50% either year are Alabama, Alaska, Arizona, Arkansas, Colorado, Florida, Georgia, Hawaii, Illinois, Iowa, Kansas, Kentucky, Louisiana, Minnesota, Mississippi, Missouri, Montana, Nebraska  Nevada, New Mexico, North Carolina, North Dakota, Ohio, Oklahoma, South Carolina, South Dakota, Tennessee,  Utah,  West Virginia, Wisconsin, Wyoming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disctrict of Columbia had one of the highest SAT participation rates in 2017 and yet had the lowest SAT total score in 2017 and 2018 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['state', 'act2017_participation_rate', 'act2017_avg_english_score',\n",
       "       'act2017_avg_math_score', 'act2017_avg_reading_score',\n",
       "       'act2017_avg_science_score', 'act2017_composite_score',\n",
       "       'sat2017_participation_rate',\n",
       "       'sat2017_avg_evidence_based_reading_and_writing_score',\n",
       "       'sat2017_avg_math_score', 'sat2017_avg_total_score',\n",
       "       'act2018_participation_rate', 'act2018_avg_english_score',\n",
       "       'act2018_avg_math_score', 'act2018_avg_reading_score',\n",
       "       'act2018_avg_science_score', 'act2018_composite_score',\n",
       "       'sat2018_participation_rate',\n",
       "       'sat2018_avg_evidence_based_reading_and_writing_score',\n",
       "       'sat2018_avg_math_score', 'sat2018_avg_total_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_merge.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Distributions in the data\n",
    "\n",
    "In this dataset, each data represents a sample from a population.                        \n",
    "For example, for ACT math test:\n",
    "- Population: the test results of all the students who take this test, nation-wide.\n",
    "- Population mean: is the national average of ACT math test (total scores/total no. of test takers) \n",
    "- Sample: the state means of ACT math test. We have 51 samples (51 states)\n",
    "\n",
    "***According to CLT, we generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores  - can we say students with higher SAT math score is better than those with lower ACT math score, or vice versa?\n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
